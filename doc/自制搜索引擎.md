# 创建倒排索引

1. wiser 步骤：
    * 获取文档编号（存到数据库得到 id）
    * 将正文编码为 utf32 ，方便得到 word 的位置信息

        * N-gram 分割字符串
        * 跳过开头空格以及不索引字符
        * 为 term 创建倒排列表
        * 合并两个倒排索引
    * 存储在缓冲区中的文档数量达到了指定的阈值时，更新存储器上的倒排索引
2. 问题：
    * 一定要编码 utf32 吗？有没有更有效的编码方案？
    * c++ string 的编码能否满足
    * wiser 需要合并倒排索引，我是否一定要跟随这种做法？


3. 技术总结：
 * 获取文章 id
 * 正文编码成 utf32 同大小的 terms
 * 用迭代器循环 utf32 正文 terms
 * 每个 term 检查是否存在，否则新增

        创建倒排列表，再加入倒排索引
 * 内存上的倒排索引还要合并到数据库中


# 文档检索流程
1. wiser 步骤：
    * 检查查询字符是否满足最短长度限制
    * 从查询字符串中提取出词元的信息 （使用分割获取倒排索引的同样方法）
    * 将从查询中提取出的词元信息按照文档频率升序排序
    * 过滤不存在的查询词元
        * id 从未出现过
        * 数据库中不存在
        * 由于更新或删除导致其倒排列表为空
    * 从数据库中获取关联到指定词元上的倒排列表
    * 根据倒排列表最大 id 的文章

2. 技术总结：
    * 用创建倒排索引的方式将查询短语分解成索引
    * 对查询索引降序排序
    * 找到所有查询词都出现的文章加入结果
    * 针对结果计算 tf-idf 值
    * 整理最终结果，并返回
    
    
# 短语检索流程
1. wiser 步骤：
    * 获取查询中词元的总数
    * 初始化游标
    * 检索短语中符合每个词元距离的文章

# 压缩文档


# 代码遭遇
1. utf8 utf16 utf32 区别
2. 为啥用 n-gram 来分割词汇，而不是 hard core (https://people.eecs.berkeley.edu/~dcoetzee/publications/TinyLex,%20Static%20N-Gram%20Index%20Pruning%20with%20Perfect%20Recall.pdf)